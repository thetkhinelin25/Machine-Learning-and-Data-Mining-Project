{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d27dff0e",
   "metadata": {},
   "source": [
    "# Adding New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeac02b",
   "metadata": {},
   "source": [
    "This notebook performs feature engineering to enhance the metadata with additional statistical and signal-based features extracted from the raw signals data. The main steps are:\n",
    "\n",
    "1. **Loading Data**\n",
    "   - Loads `signals.csv`, `metadata.csv`, and their respective test and Kaggle versions.\n",
    "\n",
    "2. **Feature Extraction**\n",
    "   - For each `user_snippet`, statistical and signal-based features are extracted for the x, y, and z axes, including:\n",
    "     - **Statistical features**: mean, std, range, IQR, MAD, skewness, kurtosis, coefficient of variation.\n",
    "     - **Rolling statistics**: rolling mean and rolling std.\n",
    "     - **Frequency-domain features**: FFT peak, spectral energy, spectral entropy.\n",
    "     - **Hjorth parameters**: mobility and complexity.\n",
    "     - **Transition-based features**: zero-crossing rate.\n",
    "\n",
    "3. **Additional Derived Features**\n",
    "   - Computes additional global features such as:\n",
    "     - **SMA (Signal Magnitude Area)**\n",
    "     - **Axis correlations** (corr_xy, corr_xz, corr_yz)\n",
    "     - **Jerk statistics** (mean and std)\n",
    "\n",
    "4. **Merging Features**\n",
    "   - All newly computed features are merged with the original `metadata.csv` to create enriched datasets.\n",
    "\n",
    "5. **Saving Outputs**\n",
    "   - The final feature-enriched datasets are saved as:\n",
    "     - `Updated_Metadata.csv`\n",
    "     - `Updated_Metadata_Test.csv`\n",
    "     - `Updated_Metadata_Kaggle.csv`\n",
    "\n",
    "These updated files serve as the training and evaluation input for all machine learning models developed in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1d2098d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-987f5201201a>:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sma_series = grouped.apply(compute_sma).rename(\"sma\")\n",
      "<ipython-input-6-987f5201201a>:95: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  correlation_df = grouped.apply(compute_correlations)\n",
      "<ipython-input-6-987f5201201a>:96: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  jerk_df = grouped.apply(compute_jerk_stats)\n",
      "<ipython-input-6-987f5201201a>:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sma_series = grouped.apply(compute_sma).rename(\"sma\")\n",
      "<ipython-input-6-987f5201201a>:95: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  correlation_df = grouped.apply(compute_correlations)\n",
      "<ipython-input-6-987f5201201a>:96: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  jerk_df = grouped.apply(compute_jerk_stats)\n",
      "<ipython-input-6-987f5201201a>:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sma_series = grouped.apply(compute_sma).rename(\"sma\")\n",
      "<ipython-input-6-987f5201201a>:95: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  correlation_df = grouped.apply(compute_correlations)\n",
      "<ipython-input-6-987f5201201a>:96: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  jerk_df = grouped.apply(compute_jerk_stats)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew, iqr\n",
    "from scipy.signal import welch\n",
    "from scipy.fft import fft\n",
    "\n",
    "# ---------- Load all data ----------\n",
    "metadata_df = pd.read_csv('metadata.csv')\n",
    "metadata_test_df = pd.read_csv('metadata_test.csv')\n",
    "metadata_kaggle_df = pd.read_csv('metadata_kaggle.csv')\n",
    "\n",
    "signals_df = pd.read_csv('signals.csv')\n",
    "signals_test_df = pd.read_csv('signals_test.csv')\n",
    "signals_kaggle_df = pd.read_csv('signals_kaggle.csv')\n",
    "\n",
    "# ---------- Statistical & Spectral Feature Extraction ----------\n",
    "def extract_features_from_signals(df):\n",
    "    feature_rows = []\n",
    "\n",
    "    for snippet_id, group in df.groupby(\"user_snippet\"):\n",
    "        feature_dict = {\"user_snippet\": snippet_id}\n",
    "\n",
    "        for axis in [\"x-axis\", \"y-axis\", \"z-axis\"]:\n",
    "            signal = group[axis].fillna(0).values\n",
    "            series = pd.Series(signal)\n",
    "\n",
    "            # Basic statistics\n",
    "            mean_val = np.mean(signal)\n",
    "            std_val = np.std(signal)\n",
    "            var_0 = np.var(signal)\n",
    "\n",
    "            # Hjorth parameters\n",
    "            first_deriv = np.diff(signal, prepend=signal[0])\n",
    "            second_deriv = np.diff(first_deriv, prepend=first_deriv[0])\n",
    "            var_d1 = np.var(first_deriv)\n",
    "            var_d2 = np.var(second_deriv)\n",
    "            mobility = np.sqrt(var_d1 / var_0) if var_0 != 0 else 0\n",
    "            complexity = np.sqrt(var_d2 / var_d1) / mobility if var_d1 != 0 else 0\n",
    "\n",
    "            # Frequency & spectral features\n",
    "            f, Pxx = welch(signal, nperseg=min(256, len(signal)))\n",
    "            Pxx_norm = Pxx / np.sum(Pxx) if np.sum(Pxx) != 0 else np.ones_like(Pxx)\n",
    "\n",
    "            # Feature dictionary updates\n",
    "            feature_dict.update({\n",
    "                f\"{axis}__fft_peak\": np.max(np.abs(fft(signal))),\n",
    "                f\"{axis}__hjorth_mobility\": mobility,\n",
    "                f\"{axis}__hjorth_complexity\": complexity,\n",
    "                f\"{axis}__rolling_mean\": series.rolling(window=5, min_periods=1).mean().mean(),\n",
    "                f\"{axis}__rolling_std\": series.rolling(window=5, min_periods=1).std().mean(),\n",
    "                f\"{axis}__zero_crossing_rate\": ((series.shift(1) * series) < 0).sum() / len(series),\n",
    "                f\"{axis}__spectral_energy\": np.sum(Pxx),\n",
    "                f\"{axis}__spectral_entropy\": -np.sum(Pxx_norm * np.log2(Pxx_norm + 1e-12)),\n",
    "                f\"{axis}__iqr\": iqr(signal),\n",
    "                f\"{axis}__coeff_var\": std_val / mean_val if mean_val != 0 else 0,\n",
    "                f\"{axis}__energy\": np.sum(signal ** 2),\n",
    "                f\"{axis}_MAD\": np.mean(np.abs(signal - mean_val)),\n",
    "                f\"{axis}_range\": np.max(signal) - np.min(signal),\n",
    "                f\"{axis}_kurtosis\": kurtosis(signal),\n",
    "                f\"{axis}_skewness\": skew(signal),\n",
    "            })\n",
    "\n",
    "        feature_rows.append(feature_dict)\n",
    "\n",
    "    return pd.DataFrame(feature_rows)\n",
    "\n",
    "# ---------- Additional Features: SMA, Correlations, Jerk ----------\n",
    "def compute_sma(group):\n",
    "    return np.mean(np.abs(group['x-axis']) + np.abs(group['y-axis']) + np.abs(group['z-axis']))\n",
    "\n",
    "def compute_correlations(group):\n",
    "    return pd.Series({\n",
    "        'corr_xy': group['x-axis'].corr(group['y-axis']),\n",
    "        'corr_xz': group['x-axis'].corr(group['z-axis']),\n",
    "        'corr_yz': group['y-axis'].corr(group['z-axis']),\n",
    "    })\n",
    "\n",
    "def compute_jerk_stats(group):\n",
    "    jerk_x = np.diff(group['x-axis']) / np.diff(group['timestamp'])\n",
    "    jerk_y = np.diff(group['y-axis']) / np.diff(group['timestamp'])\n",
    "    jerk_z = np.diff(group['z-axis']) / np.diff(group['timestamp'])\n",
    "    return pd.Series({\n",
    "        'jerk_x_mean': np.mean(jerk_x),\n",
    "        'jerk_x_std': np.std(jerk_x),\n",
    "        'jerk_y_mean': np.mean(jerk_y),\n",
    "        'jerk_y_std': np.std(jerk_y),\n",
    "        'jerk_z_mean': np.mean(jerk_z),\n",
    "        'jerk_z_std': np.std(jerk_z),\n",
    "    })\n",
    "\n",
    "def enrich_metadata(signals_df, base_metadata):\n",
    "    features = extract_features_from_signals(signals_df)\n",
    "    grouped = signals_df.groupby('user_snippet')\n",
    "    sma_series = grouped.apply(compute_sma).rename(\"sma\")\n",
    "    correlation_df = grouped.apply(compute_correlations)\n",
    "    jerk_df = grouped.apply(compute_jerk_stats)\n",
    "    more_features = pd.concat([sma_series, correlation_df, jerk_df], axis=1).reset_index()\n",
    "    metadata_enriched = pd.merge(base_metadata, features, on='user_snippet', how='left')\n",
    "    metadata_enriched = pd.merge(metadata_enriched, more_features, on='user_snippet', how='left')\n",
    "    return metadata_enriched\n",
    "\n",
    "# ---------- Apply to all datasets ----------\n",
    "metadata_all = enrich_metadata(signals_df, metadata_df)\n",
    "metadata_test_all = enrich_metadata(signals_test_df, metadata_test_df)\n",
    "metadata_kaggle_all = enrich_metadata(signals_kaggle_df, metadata_kaggle_df)\n",
    "\n",
    "# ---------- Save to CSV ----------\n",
    "metadata_all.to_csv('Updated_Metadata.csv', index=False)\n",
    "metadata_test_all.to_csv('Updated_Metadata_Test.csv', index=False)\n",
    "metadata_kaggle_all.to_csv('Updated_Metadata_Kaggle.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883aee09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871326e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
